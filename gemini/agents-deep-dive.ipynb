{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d771ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "  langchain-core  \\\n",
    "  langchain[google-genai]  \\\n",
    "  langchain-community  \\\n",
    "  langsmith  \\\n",
    "  google-search-results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "638856c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Google Gemini: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "#llm = GoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0.0) \n",
    "\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13afbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Define the multiply tool\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "# Define the exponentiate tool\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167ad402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt= ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "    \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )), \n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42ec055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "003c1ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"x\": 10.0, \"y\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--6b0338d8-33e6-4d36-9754-2169b414a957-0', tool_calls=[{'name': 'add', 'args': {'x': 10.0, 'y': 10.0}, 'id': 'fd7f9891-4ccc-4620-94ca-9198d4a17cbf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 276, 'output_tokens': 82, 'total_tokens': 358, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 62}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f644f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': <function __main__.add(x: float, y: float) -> float>,\n",
       " 'subtract': <function __main__.subtract(x: float, y: float) -> float>,\n",
       " 'multiply': <function __main__.multiply(x: float, y: float) -> float>,\n",
       " 'exponentiate': <function __main__.exponentiate(x: float, y: float) -> float>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "name2tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "230cfec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566e2578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"x\": 10.0, \"y\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--7e845403-e5b7-48bf-9ed5-953ec7ed540d-0', tool_calls=[{'name': 'add', 'args': {'x': 10.0, 'y': 10.0}, 'id': '9c5e595c-d638-4856-9ee3-a4c1992599b7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 318, 'output_tokens': 116, 'total_tokens': 434, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 96}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content = f\"The { tool_call.tool_calls[0]['name'] }  tool returned {tool_exec_content}\",\n",
    "    tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke(\n",
    "    {\n",
    "        \"input\": \"What is 10 + 10\",\n",
    "        \"chat_history\": [],\n",
    "        \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "    }\n",
    ")\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ba656b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'add', 'arguments': '{\"x\": 10.0, \"y\": 10.0}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--cfdb62ca-e8e2-46d1-acd7-e8d9d93a6d48-0', tool_calls=[{'name': 'add', 'args': {'x': 10.0, 'y': 10.0}, 'id': '99708116-5fd5-45a0-8da1-46527c81320f', 'type': 'tool_call'}], usage_metadata={'input_tokens': 276, 'output_tokens': 81, 'total_tokens': 357, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 61}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
    ")\n",
    "\n",
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "151bf75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 + 10 = 20.0', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--93eebdfa-1a89-4364-a2cd-763b32097cdd-0', usage_metadata={'input_tokens': 317, 'output_tokens': 12, 'total_tokens': 329, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_output}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a750f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used:list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9776608",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
    "\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c591a5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10.0, 'y': 10.0},\n",
       "  'id': 'f46e7a84-f463-4bfc-93f7-ea2d44998c04',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84eac2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'final_answer', 'arguments': '{\"answer\": \"10 + 10 is 20.\", \"tools_used\": [\"add\"]}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--bc72ec75-46c9-405c-910d-44c4819a478b-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': '10 + 10 is 20.', 'tools_used': ['add']}, 'id': '1af1eceb-201c-4dec-b44d-04cc8a73d2e3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 421, 'output_tokens': 96, 'total_tokens': 517, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 65}})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f9b0dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '10 + 10 is 20.', 'tools_used': ['add']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63330bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, BaseMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38cace07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chat_history = [] \n",
    "        \n",
    "        self.agent: RunnableSerializable= (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])                \n",
    "            }\n",
    "            | prompt\n",
    "            | llm.bind_tools(tools, tool_choice = \"any\")\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def invoke(self, input: str, max_iterations:int = 3) -> dict:\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "        while count < self.max_iterations:\n",
    "            tool_call = self.agent.invoke({\n",
    "                \"input\": input,\n",
    "                \"chat_history\": self.chat_history,\n",
    "                \"agent_scratchpad\": agent_scratchpad\n",
    "            })\n",
    "            \n",
    "            agent_scratchpad.append(tool_call)\n",
    "            \n",
    "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
    "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
    "            tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    "            tool_out = name2tool[tool_name](**tool_args)\n",
    "            \n",
    "            tool_exec = ToolMessage(\n",
    "                content = tool_out,\n",
    "                tool_call_id = tool_call_id\n",
    "            )\n",
    "            \n",
    "            agent_scratchpad.append(tool_exec)\n",
    "            print(f\"{count}: {tool_name}({tool_args})\")\n",
    "            count += 1\n",
    "            \n",
    "            if tool_name == \"final_answer\":\n",
    "                break\n",
    "        \n",
    "        if isinstance(tool_out, dict) and \"answer\" in tool_out:\n",
    "            final_answer = tool_out[\"answer\"]\n",
    "            self.chat_history.extend([\n",
    "                HumanMessage(content=input),\n",
    "                AIMessage(content=final_answer)\n",
    "            ])\n",
    "            return json.dumps(tool_out)\n",
    "\n",
    "        print(\"Need more iterations to get the answer\")\n",
    "        \n",
    "        return json.dumps({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "859e571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor_custom = CustomAgentExecutor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bfd727b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: add({'x': 10.0, 'y': 10.0})\n",
      "1: final_answer({'answer': '10 + 10 = 20', 'tools_used': ['add']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"answer\": \"10 + 10 = 20\", \"tools_used\": [\"add\"]}'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor_custom.invoke(input = \"What is 10 + 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "872d8e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: exponentiate({'x': 2.0, 'y': 3.0})\n",
      "1: multiply({'x': 4.0, 'y': 8.0})\n",
      "2: add({'x': 9.0, 'y': 10.0})\n",
      "3: subtract({'x': 32.0, 'y': 19.0})\n",
      "4: final_answer({'answer': 'The result is -13.', 'tools_used': ['exponentiate', 'multiply', 'add', 'subtract']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"answer\": \"The result is -13.\", \"tools_used\": [\"exponentiate\", \"multiply\", \"add\", \"subtract\"]}'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor_custom.invoke(input = \"What is nine plus 10, minus 4 * 2 to the power of 3\", max_iterations = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037efb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
