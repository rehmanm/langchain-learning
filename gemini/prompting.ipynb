{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df725308",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "  langchain-core \\\n",
    "  langchain-google-genai \\\n",
    "  langchain-community \\\n",
    "  scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c59d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Answer the user's query based on the context below.\n",
    "If you don't know the answer based on the context\n",
    "provided, please respond, I don't know.\n",
    "\n",
    "---\n",
    "Context: {context}\n",
    "---\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", prompt),\n",
    "        (\"user\", \"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef411e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb13bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "prompt_template_2 = ChatPromptTemplate.from_messages([\n",
    "        SystemMessagePromptTemplate.from_template(prompt),\n",
    "        HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_2.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baeb966",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_2.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2271103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\", temperature=0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c471e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = (\n",
    "    {\n",
    "        \"query\": lambda x: x[\"query\"],\n",
    "        \"context\": lambda x: x[\"context\"]\n",
    "    }\n",
    "    | prompt_template_2 \n",
    "    | llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087ea597",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Aurelio AI is an AI company developing tooling for AI\n",
    "engineers. There focus is on the language AI with the team having strong\n",
    "expertise in building AI agents and a strong background in information\n",
    "retreival.\n",
    "\n",
    "The company is behind several open source frameworks, most notably\n",
    "Semantic Router and Semantic Chunkers. They also have an AI \n",
    "Platform providing engineers with tooling to help them build with \n",
    "AI. Finally, the team also provides development services to other\n",
    "organizations to help them bring their AI tech to market.\n",
    "\n",
    "Aurelio AI become langchain expert in September 2024 after a long \n",
    "track record of delivering AI solutions built with Langchain ecosystem.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "query =\"What does Aurelio AI do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.invoke({\"query\": query, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.invoke({\"query\": \"What does Microsoft do\", \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c52cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
