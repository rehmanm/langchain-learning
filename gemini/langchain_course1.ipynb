{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b194d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "  langchain-core \\\n",
    "  langchain-google-genai \\\n",
    "  langchain-community \\\n",
    "  scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9baa3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for Google Gemini: ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f76724b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\", temperature=0.0)\n",
    "creative_llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\", temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9802a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"\n",
    "\n",
    "Introduction\n",
    "The future of automation is with “Agents”. Whereas, in the business automations, there isn't an easy solution to get the functionality done. In the present day and age of intelligent automation, it is highly crucial to develop powerful platforms and tools. Such a vast combination is Bright Data, LangChain, and Google Gemini. Bright Data facilitates web-scale data extraction, LangChain facilitates developing advanced language models and chains, and Google Gemini provides premium summarization capabilities.\n",
    "\n",
    "This blog post will take you through a real-world use case integrating these technologies to create an intelligent agent that can execute Google search queries via Bright Data, scrape Airbnb listings, and return summarized insights from the results. You will be demonstrated with the usage of LangChain to organize your workflow and Google Gemini for summarization so that the output is actionable, meaningful, and concise.\n",
    "\n",
    "New users of Bright Data, please make sure to sign-up here - Bright Data\n",
    "\n",
    "Who is this for?\n",
    "\n",
    "This solution is ideal for:\n",
    "\n",
    "• Data Engineers and Data Scientists: Wishing to create an intelligent agent that can gather, process, and abstract data from diverse sources.\n",
    "\n",
    "• Developers: Wanting to incorporate APIs and create sophisticated applications with the help of LangChain and other third-party platforms such as Bright Data and Google Gemini.\n",
    "\n",
    "• Business Analysts and Product Managers: Who wish to find means of deriving insights from two platforms (Google and Airbnb) and summarizing the data for faster decision-making.\n",
    "\n",
    "What problem is this workflow solving?\n",
    "\n",
    "Actionable information quickly is always critical. Traditional data extraction methods are often slow, error-prone, and require significant manual effort.\n",
    "\n",
    "This workflow solves the following problems:\n",
    "\n",
    "Web scraping complexity: Automating the extraction of data from websites like Google and Airbnb in a structured and scalable manner.\n",
    "Search optimization: Refining Google search results and presenting them in a meaningful way, specifically for business applications like competitive analysis or market research.\n",
    "Summarization: Aggregating data and providing concise summaries using advanced AI techniques to ensure that key insights are easily consumable.\n",
    "What this workflow does\n",
    "\n",
    "The core of this workflow is a LangChain agent that:\n",
    "\n",
    "Performs a Google search using the Bright Data SERP API.\n",
    "Scrapes Airbnb listings from a specific location using the Bright Data Web Unlocker.\n",
    "Summarizes the results using Google Gemini.\n",
    "Detailed Breakdown of the Process\n",
    "\n",
    "Scraping Airbnb Listings: With a location input, the agent scrapes Airbnb listings using Bright Data Web Unlocker, which provides access to dynamic content such as property details (price, location, amenities).\n",
    "Google Search via Bright Data SERP API: The workflow first sends a search query to Google using Bright Data’s SERP API. This API allows us to bypass search engine restrictions and retrieve organic search results (titles, snippets, URLs) for a given query.\n",
    "Summarization with Google Gemini: Once the data is retrieved, Google Gemini is used to summarize the results. The model condenses the large set of information into a few concise points, allowing the user to quickly understand the key insights without having to read through every detail.\n",
    "Setup\n",
    "\n",
    "To set up this workflow, follow the steps below:\n",
    "\n",
    "1. Install Required Libraries\n",
    "\n",
    "Before getting started, ensure that you have all necessary libraries installed. You can use the following requirements.txt file to manage dependencies:\n",
    "\n",
    "2. Set Up API Keys\n",
    "\n",
    "Bright Data: You will need an API key for the Bright Data SERP API and Web Unlocker. Sign up for an account on Bright Data and retrieve your API keys from the dashboard.\n",
    "Google Gemini: You need an API key to access the Google Gemini model. Set up the necessary authentication and obtain an API key from the Google Cloud Console.\n",
    "3. Environment Variables\n",
    "\n",
    "To securely store your API keys, use a .env file. This ensures that your credentials are not exposed in your codebase.\n",
    "\n",
    "BRIGHTDATA_SERP_API_KEY=your_brightdata_api_key\n",
    "\n",
    "BRIGHTDATA_BEARER_TOKEN=your_brightdata_bearer_token\n",
    "\n",
    "GOOGLE_API_KEY=your_google_api_key\n",
    "\n",
    "GOOGLE_GEMINI_MODEL_NAME=your_google_gemini_model_name\n",
    "\n",
    "4. Write the LangChain Agent\n",
    "\n",
    "Now that all dependencies are in place, let's write the LangChain agent. This agent will interact with Bright Data, scrape the necessary information, and pass it through Google Gemini for summarization.\n",
    "\n",
    "Code for the LangChain Agent:\n",
    "\n",
    "Source Code LangChain-BrightData-Agent\n",
    "\n",
    "Here’s the crucial agent implementation which utilizes the Bright Data, Airbnb and Google Gemini providers.\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "from tools.google_search import GoogleSearchTool\n",
    "from tools.airbnb import AirbnbTool\n",
    "from gemini_summary import summarize_with_gemini\n",
    "from llm import GeminiLLM\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = GeminiLLM()\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(func=GoogleSearchTool(), name=\"Google Search\", description=\"Search Google for answers\"),\n",
    "    Tool.from_function(func=AirbnbTool(), name=\"Airbnb Search\", description=\"Search Airbnb for listings\")\n",
    "]\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Find Airbnb listings in New York and summarize Google reviews about staying there.\"\n",
    "    try:\n",
    "        result = agent.run(query)\n",
    "        summary = summarize_with_gemini(result)\n",
    "        print(\"\\n===== RAW RESULT =====\")\n",
    "        print(result)\n",
    "        print(\"\\n===== SUMMARY =====\")\n",
    "        print(summary)\n",
    "    except Exception as e:\n",
    "        print(f\"[Agent Error] {e}\")\n",
    "How to Customize this Workflow to Your Needs\n",
    "\n",
    "Modify Search Queries: You can change the search query by modifying the query variable. This allows the agent to search for different topics, products, or services.\n",
    "Summarization Settings: If you want a different style or level of detail for the summaries, update the gemini_summary.py with the prompt template for summarization.\n",
    "Add More Tools: LangChain allows for easily adding new tools. You can integrate other web scraping tools, APIs, or services to extend this agent's capabilities.\n",
    "Source Code\n",
    "\n",
    "Here's the Source Code LangChain-BrightData-Agent\n",
    "\n",
    "Conclusion\n",
    "\n",
    "By integrating Bright Data, LangChain, and Google Gemini, you can build an intelligent agent that efficiently scrapes data, processes it, and gives insightful answers in the form of summaries. This process can be further tailored to adapt to various applications, including competitive research, market analysis, or vacation planning.\n",
    "\n",
    "Content Credits - This blog-post contents were formatted with ChatGPT to make it more professional and produce a polished content for the targeted audience.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea5629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eccf05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI assistant that helps generate article titles\"\n",
    ")\n",
    "\n",
    "user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are tasked with creating a name for an article.\n",
    "    The article here is for you to examine \n",
    "    \n",
    "    ---\n",
    "    \n",
    "    {article}\n",
    "    \n",
    "    ---\n",
    "    The name should be based on the context of the article.\n",
    "    Be creative, but make sure names are clear, catchy,\n",
    "    and relevant to the theme of the article.\n",
    "    \n",
    "    Only output the article name, no other explaination or \n",
    "    text can be provided.   \n",
    "    \n",
    "    \"\"\",\n",
    "        input_variables = [\"article\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fdc2256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    You are tasked with creating a name for an article.\\n    The article here is for you to examine \\n    \\n    ---\\n    \\n    TEST String\\n    \\n    ---\\n    The name should be based on the context of the article.\\n    Be creative, but make sure names are clear, catchy,\\n    and relevant to the theme of the article.\\n    \\n    Only output the article name, no other explaination or \\n    text can be provided.   \\n    \\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt.format(article = \"TEST String\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b1e148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are tasked with creating a name for an article.\n",
      "    The article here is for you to examine \n",
      "    \n",
      "    ---\n",
      "    \n",
      "    TEST String\n",
      "    \n",
      "    ---\n",
      "    The name should be based on the context of the article.\n",
      "    Be creative, but make sure names are clear, catchy,\n",
      "    and relevant to the theme of the article.\n",
      "    \n",
      "    Only output the article name, no other explaination or \n",
      "    text can be provided.   \n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(user_prompt.format(article = \"TEST String\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db3b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bddc2b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_prompt = ChatPromptTemplate.from_messages([system_prompt, user_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba110900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an AI assistant that helps generate article titles\n",
      "Human: \n",
      "    You are tasked with creating a name for an article.\n",
      "    The article here is for you to examine \n",
      "    \n",
      "    ---\n",
      "    \n",
      "    TEST STRING\n",
      "    \n",
      "    ---\n",
      "    The name should be based on the context of the article.\n",
      "    Be creative, but make sure names are clear, catchy,\n",
      "    and relevant to the theme of the article.\n",
      "    \n",
      "    Only output the article name, no other explaination or \n",
      "    text can be provided.   \n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(first_prompt.format(article = \"TEST STRING\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d1ca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_one = (\n",
    "    {\"article\": lambda x: x[\"article\"]}\n",
    "    | first_prompt\n",
    "    | creative_llm\n",
    "    | { \"article_title\": lambda x: x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a722f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article_title': 'Building an Intelligent Agent: Bright Data, LangChain, and Google Gemini for Data Extraction and Summarization'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_title_msg = chain_one.invoke({\n",
    "    \"article\": article\n",
    "})\n",
    "article_title_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "652d5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are tasked with creating a description for\n",
    "    the article. The article is here for you to examine.\n",
    "    \n",
    "    ---\n",
    "    {article}\n",
    "    ---\n",
    "    Here is the article title {article_title}\n",
    "    \n",
    "    Output the SEO freindly article description. Make sure don't exceed\n",
    "    200 characters. Do not output\n",
    "    anything other than the description.\n",
    "    \n",
    "    \"\"\",\n",
    "    input_variables = [\"article\", \"article_title\"]\n",
    ")\n",
    "\n",
    "second_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_prompt,\n",
    "    second_user_prompt\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bd99692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an AI assistant that helps generate article titles\n",
      "Human: \n",
      "    You are tasked with creating a description for\n",
      "    the article. The article is here for you to examine.\n",
      "    \n",
      "    ---\n",
      "    TEST STRING\n",
      "    ---\n",
      "    Here is the article title TEST Title\n",
      "    \n",
      "    Output the SEO freindly article description. Make sure don't exceed\n",
      "    200 characters. Do not output\n",
      "    anything other than the description.\n",
      "    \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(second_prompt.format(article = \"TEST STRING\", article_title = \"TEST Title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e43422",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_two = (\n",
    "    {\"article\": lambda x: x[\"article\"],\n",
    "     \"article_title\": lambda x: x[\"article_title\"]}\n",
    "    | second_prompt\n",
    "    | creative_llm\n",
    "    | { \"summary\": lambda x: x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "083ba256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Automate data extraction & summarization with Bright Data, LangChain, & Google Gemini. Build an intelligent agent for insights from web data!'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_description_msg = chain_two.invoke({\n",
    "    \"article\": article,\n",
    "    \"article_title\": article_title_msg\n",
    "})\n",
    "article_description_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e323ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_two_llm = (\n",
    "    {\"article\": lambda x: x[\"article\"],\n",
    "     \"article_title\": lambda x: x[\"article_title\"]}\n",
    "    | second_prompt\n",
    "    | llm\n",
    "    | { \"summary\": lambda x: x.content}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d638c465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Automate data extraction & summarization with Bright Data, LangChain, & Google Gemini. Build an intelligent agent for insights from web data!'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_description_msg_llm = chain_two.invoke({\n",
    "    \"article\": article,\n",
    "    \"article_title\": article_title_msg\n",
    "})\n",
    "article_description_msg_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f195edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_user_prompt = HumanMessagePromptTemplate.from_template(\n",
    "\"\"\"\n",
    "    You are tasked with creating a paragraph from the article. The\n",
    "    article for you to examine:\n",
    "    ---\n",
    "    {article}\n",
    "    ---\n",
    "    \n",
    "    Choose one paragraph to review and edit. During your edit ensure you provide\n",
    "    constructive feedback to the user, so they can learn where to improve their writing.\n",
    "\"\"\", input_variables = [\"article\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78aa3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_prompt,\n",
    "    third_user_prompt\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc6877c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Paragraph(BaseModel):\n",
    "    original_paragraph: str = Field(description = \"The original paragraph\")\n",
    "    edited_paragraph: str = Field(description = \"The improved edited paragraph\")\n",
    "    feedback: str = Field(description = \"The constructive feedback\")\n",
    "    feedback_score: int = Field(description = \"The constructive feedback score\")\n",
    "\n",
    "structured_llm = creative_llm.with_structured_output(Paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08084f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_three = (\n",
    "    { \"article\": lambda x: x[\"article\"]}\n",
    "    | third_prompt\n",
    "    | structured_llm\n",
    "    | {\n",
    "        \"original_paragraph\": lambda x: x.original_paragraph,\n",
    "        \"edited_paragraph\": lambda x: x.edited_paragraph,\n",
    "        \"feedback\": lambda x: x.feedback,\n",
    "        \"feedback_score\": lambda x: x.feedback_score,\n",
    "    }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81c75b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original_paragraph': \"Whereas, in the business automations, there isn't an easy solution to get the functionality done. In the present day and age of intelligent automation, it is highly crucial to develop powerful platforms and tools. Such a vast combination is Bright Data, LangChain, and Google Gemini. Bright Data facilitates web-scale data extraction, LangChain facilitates developing advanced language models and chains, and Google Gemini provides premium summarization capabilities.\", 'edited_paragraph': \"In the realm of business automation, a straightforward solution for achieving desired functionality is often elusive. However, the convergence of Bright Data, LangChain, and Google Gemini offers a powerful combination in today's era of intelligent automation. Bright Data excels in facilitating web-scale data extraction, LangChain enables the development of advanced language models and chains, and Google Gemini provides premium summarization capabilities.\", 'feedback': 'The revised paragraph enhances clarity and flow by restructuring the initial sentence and using more precise language to describe the capabilities of each technology. It also maintains a professional tone suitable for the intended audience.', 'feedback_score': 9}\n"
     ]
    }
   ],
   "source": [
    "out = chain_three.invoke({\"article\": article})\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "689351fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "image_prompt = PromptTemplate(\n",
    "    input_variables = [\"article\"],\n",
    "    template = (\n",
    "    \"\"\"\n",
    "    Generate a prompt with less than 500 characters to generate an image\n",
    "    based on following article\n",
    "    ---\n",
    "    {article}\n",
    "    ---\n",
    "    \"\"\"\n",
    "               )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea276fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rehmanm/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def generate_and_display_image(image_prompt):\n",
    "    print(image_prompt)\n",
    "    \n",
    "    image_url = DallEAPIWrapper().run(image_prompt)\n",
    "    image_date = io.imread(image_url)\n",
    "    \n",
    "    plt.imshow(image_data)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show\n",
    "    \n",
    "\n",
    "img_gen_runnable = RunnableLambda(generate_and_display_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11180d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_four = (\n",
    "    {\"article\": lambda x: x[\"article\"]}\n",
    "    | image_prompt\n",
    "    | llm\n",
    "    | (lambda x: x.content)\n",
    "    | img_gen_runnable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a7beb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI agent scraping Airbnb listings and summarizing Google reviews, powered by Bright Data, LangChain, and Google Gemini.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import openai python package. Please install it with `pip install openai`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/utilities/dalle_image_generator.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3219/583040180.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchain_four\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"article\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3044\u001b[0m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3045\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3046\u001b[0;31m                         \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3047\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3048\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4773\u001b[0m         \"\"\"\n\u001b[1;32m   4774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4775\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m   4776\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invoke\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4777\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1937\u001b[0m                 output = cast(\n\u001b[1;32m   1938\u001b[0m                     \u001b[0;34m\"Output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1939\u001b[0;31m                     context.run(\n\u001b[0m\u001b[1;32m   1940\u001b[0m                         \u001b[0mcall_func_with_variable_args\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1941\u001b[0m                         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m_invoke\u001b[0;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   4631\u001b[0m                         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4633\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m   4634\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4635\u001b[0m             )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3219/3027537958.py\u001b[0m in \u001b[0;36mgenerate_and_display_image\u001b[0;34m(image_prompt)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimage_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDallEAPIWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_prompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mimage_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/utilities/dalle_image_generator.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0;34m\"Could not import openai python package. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;34m\"Please install it with `pip install openai`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import openai python package. Please install it with `pip install openai`."
     ]
    }
   ],
   "source": [
    "chain_four.invoke({\"article\": article})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bccfb82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
